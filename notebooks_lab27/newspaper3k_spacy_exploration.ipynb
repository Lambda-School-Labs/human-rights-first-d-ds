{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PRAW Notebook 2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfjjK_EcyNfl",
        "colab_type": "text"
      },
      "source": [
        "## Install modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfMYp7uc6qmz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "53131722-f9a4-4d76-c6e3-a171d3bfe14b"
      },
      "source": [
        "!pip install praw\n",
        "!pip3 install newspaper3k"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting praw\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/15/4bcc44271afce0316c73cd2ed35f951f1363a07d4d5d5440ae5eb2baad78/praw-7.1.0-py3-none-any.whl (152kB)\n",
            "\r\u001b[K     |██▏                             | 10kB 18.0MB/s eta 0:00:01\r\u001b[K     |████▎                           | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 30kB 2.3MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 40kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 61kB 2.3MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 71kB 2.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 81kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 92kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 133kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 143kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 153kB 2.8MB/s \n",
            "\u001b[?25hCollecting prawcore<2.0,>=1.3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/1d/40/b741437ce4c7b64f928513817b29c0a615efb66ab5e5e01f66fe92d2d95b/prawcore-1.5.0-py3-none-any.whl\n",
            "Collecting update-checker>=0.17\n",
            "  Downloading https://files.pythonhosted.org/packages/0c/ba/8dd7fa5f0b1c6a8ac62f8f57f7e794160c1f86f31c6d0fb00f582372a3e4/update_checker-0.18.0-py3-none-any.whl\n",
            "Collecting websocket-client>=0.54.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/5f/f61b420143ed1c8dc69f9eaec5ff1ac36109d52c80de49d66e0c36c3dfdf/websocket_client-0.57.0-py2.py3-none-any.whl (200kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 11.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3.0,>=2.6.0 in /usr/local/lib/python3.6/dist-packages (from prawcore<2.0,>=1.3.0->praw) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from websocket-client>=0.54.0->praw) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0,>=2.6.0->prawcore<2.0,>=1.3.0->praw) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0,>=2.6.0->prawcore<2.0,>=1.3.0->praw) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0,>=2.6.0->prawcore<2.0,>=1.3.0->praw) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0,>=2.6.0->prawcore<2.0,>=1.3.0->praw) (2020.6.20)\n",
            "Installing collected packages: prawcore, update-checker, websocket-client, praw\n",
            "Successfully installed praw-7.1.0 prawcore-1.5.0 update-checker-0.18.0 websocket-client-0.57.0\n",
            "Collecting newspaper3k\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/b9/51afecb35bb61b188a4b44868001de348a0e8134b4dfa00ffc191567c4b9/newspaper3k-0.2.8-py3-none-any.whl (211kB)\n",
            "\u001b[K     |████████████████████████████████| 215kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (4.2.6)\n",
            "Requirement already satisfied: PyYAML>=3.11 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (3.13)\n",
            "Collecting jieba3k>=0.35.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/cb/2c8332bcdc14d33b0bedd18ae0a4981a069c3513e445120da3c3f23a8aaa/jieba3k-0.35.1.zip (7.4MB)\n",
            "\u001b[K     |████████████████████████████████| 7.4MB 8.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (4.6.3)\n",
            "Collecting tldextract>=2.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/12/cf/d0ff82625e53bd245d6173ce6333d190abbfcd94e4c30e54b4e16b474216/tldextract-2.2.3-py2.py3-none-any.whl (48kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.7MB/s \n",
            "\u001b[?25hCollecting feedfinder2>=0.0.4\n",
            "  Downloading https://files.pythonhosted.org/packages/35/82/1251fefec3bb4b03fd966c7e7f7a41c9fc2bb00d823a34c13f847fd61406/feedfinder2-0.0.4.tar.gz\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (2.8.1)\n",
            "Collecting tinysegmenter==0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/17/82/86982e4b6d16e4febc79c2a1d68ee3b707e8a020c5d2bc4af8052d0f136a/tinysegmenter-0.3.tar.gz\n",
            "Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (2.23.0)\n",
            "Collecting cssselect>=0.9.2\n",
            "  Downloading https://files.pythonhosted.org/packages/3b/d4/3b5c17f00cce85b9a1e6f91096e1cc8e8ede2e1be8e96b87ce1ed09e92c5/cssselect-1.1.0-py2.py3-none-any.whl\n",
            "Collecting feedparser>=5.2.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/d8/7d37fec71ff7c9dbcdd80d2b48bcdd86d6af502156fc93846fb0102cb2c4/feedparser-5.2.1.tar.bz2 (192kB)\n",
            "\u001b[K     |████████████████████████████████| 194kB 43.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk>=3.2.1 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (3.2.5)\n",
            "Requirement already satisfied: Pillow>=3.3.0 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (7.0.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.6/dist-packages (from tldextract>=2.0.1->newspaper3k) (2.10)\n",
            "Collecting requests-file>=1.4\n",
            "  Downloading https://files.pythonhosted.org/packages/77/86/cdb5e8eaed90796aa83a6d9f75cfbd37af553c47a291cd47bc410ef9bdb2/requests_file-1.5.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from feedfinder2>=0.0.4->newspaper3k) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->newspaper3k) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->newspaper3k) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->newspaper3k) (1.24.3)\n",
            "Building wheels for collected packages: jieba3k, feedfinder2, tinysegmenter, feedparser\n",
            "  Building wheel for jieba3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jieba3k: filename=jieba3k-0.35.1-cp36-none-any.whl size=7398406 sha256=8d1009d85c68f80237d953504189f78082a665de8fdd1c0233498f760f4d1c12\n",
            "  Stored in directory: /root/.cache/pip/wheels/83/15/9c/a3f1f67e7f7181170ad37d32e503c35da20627c013f438ed34\n",
            "  Building wheel for feedfinder2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for feedfinder2: filename=feedfinder2-0.0.4-cp36-none-any.whl size=3355 sha256=30e01fca8b8b159650958f616d592aa7a07d0a094030805f603206320bbc3460\n",
            "  Stored in directory: /root/.cache/pip/wheels/de/03/ca/778e3a7a627e3d98836cc890e7cb40c7575424cfd3340f40ed\n",
            "  Building wheel for tinysegmenter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tinysegmenter: filename=tinysegmenter-0.3-cp36-none-any.whl size=13538 sha256=e6f1044f0f82fb21ecd5a4ebc88e258a4cb0a07dc3389e05f656b9e5f7d5c827\n",
            "  Stored in directory: /root/.cache/pip/wheels/81/2b/43/a02ede72324dd40cdd7ca53aad718c7710628e91b8b0dc0f02\n",
            "  Building wheel for feedparser (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for feedparser: filename=feedparser-5.2.1-cp36-none-any.whl size=44939 sha256=885980e0aa71adbb81ec5e1c85810812a2dce768c9ce21be7b4323843a5a89b3\n",
            "  Stored in directory: /root/.cache/pip/wheels/8c/69/b7/f52763c41c5471df57703a0ef718a32a5e81ee35dcf6d4f97f\n",
            "Successfully built jieba3k feedfinder2 tinysegmenter feedparser\n",
            "Installing collected packages: jieba3k, requests-file, tldextract, feedfinder2, tinysegmenter, cssselect, feedparser, newspaper3k\n",
            "Successfully installed cssselect-1.1.0 feedfinder2-0.0.4 feedparser-5.2.1 jieba3k-0.35.1 newspaper3k-0.2.8 requests-file-1.5.1 tinysegmenter-0.3 tldextract-2.2.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bO3zprDpyT0w",
        "colab_type": "text"
      },
      "source": [
        "## Import functions and grabbing reddit data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEuGLNHa7s_i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "8b1990ff-bc40-4776-ef1d-eb6ff6de9ce3"
      },
      "source": [
        "import praw\n",
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "from newspaper import Article\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "# Reddit credentials, password stored in .env \n",
        "# PRAW setup goes here"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ml43DtIn_jJ9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "881032b0-1410-4f57-c715-96ded33813ba"
      },
      "source": [
        "# Grabbing 100 hottest posts on Reddit at the moment. Will filter for police use of force later\n",
        "\n",
        "data = []\n",
        "\n",
        "# other possible subreddits: publicfreakout, allcopnodonut\n",
        "for submission in reddit.subreddit(\"news\").hot(limit=100):\n",
        "  data.append([submission.id, submission.title, submission.url])\n",
        "\n",
        "# We'll need a way to get coordinates for a given post, before we include that in df\n",
        "col_names = ['id', 'title', 'url']\n",
        "df = pd.DataFrame(data, columns=col_names)\n",
        "\n",
        "df.head()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>url</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ilsnn1</td>\n",
              "      <td>Rochester police officer tells activist she's ...</td>\n",
              "      <td>https://www.wxxinews.org/post/rochester-police...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>iltx3x</td>\n",
              "      <td>Drone drops hundreds of bags of cannabis in Te...</td>\n",
              "      <td>https://www.jpost.com/israel-news/drone-drops-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ill2g8</td>\n",
              "      <td>U.S. court: Mass surveillance program exposed ...</td>\n",
              "      <td>https://www.reuters.com/article/us-usa-nsa-spy...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ilqqqf</td>\n",
              "      <td>US gives first-ever OK for small commercial nu...</td>\n",
              "      <td>https://apnews.com/910766c07afd96fbe2bd875e160...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ilg8xj</td>\n",
              "      <td>COVID-19 has killed more police officers this ...</td>\n",
              "      <td>https://www.seattletimes.com/nation-world/covi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       id  ...                                                url\n",
              "0  ilsnn1  ...  https://www.wxxinews.org/post/rochester-police...\n",
              "1  iltx3x  ...  https://www.jpost.com/israel-news/drone-drops-...\n",
              "2  ill2g8  ...  https://www.reuters.com/article/us-usa-nsa-spy...\n",
              "3  ilqqqf  ...  https://apnews.com/910766c07afd96fbe2bd875e160...\n",
              "4  ilg8xj  ...  https://www.seattletimes.com/nation-world/covi...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8dWtaCpyfmz",
        "colab_type": "text"
      },
      "source": [
        "## Deprecated tag based filtering system"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8qgYIkMkmnN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "5a4e059e-85cc-48c0-c558-f23762c82c52"
      },
      "source": [
        "# set up some sort of corpus of keywords to snag specific reddit entries\n",
        "all_locs = pd.read_json('https://raw.githubusercontent.com/2020PB/police-brutality/data_build/all-locations-v2.json')\n",
        "all_locs = pd.json_normalize(all_locs['data'])\n",
        "all_locs = all_locs.drop(columns=['edit_at','id'])\n",
        "def cleanlinks(json):\n",
        "    links_out = []\n",
        "    for link in json:\n",
        "        links_out.append(link['url'])\n",
        "    return links_out\n",
        "all_locs['links'] = all_locs['links'].apply(cleanlinks)\n",
        "all_locs['date'] = pd.to_datetime(all_locs['date'],format='%Y-%m-%d')\n",
        "all_tags = all_locs['tags'].copy()\n",
        "tags = set()\n",
        "for taglist in all_tags:\n",
        "  for tag in taglist:\n",
        "    if tag not in tags:\n",
        "      tags.add(tag)\n",
        "# manually remove needless tags\n",
        "print(tags)\n",
        "tags.discard('')\n",
        "tags.discard('medic')\n",
        "tags.discard('bike')\n",
        "tags.discard('non-protest')\n",
        "tags.discard('pregnant')\n",
        "tags.discard('lgbtq+')\n",
        "tags.discard('racial-profiling')\n",
        "tags.discard('legal-observer')\n",
        "tags.discard('tear-gas-canister')\n",
        "tags.discard('politician')\n",
        "tags.discard('incitement')\n",
        "tags.discard('homeless')\n",
        "tags.discard('shoot')\n",
        "tags.discard('strike')\n",
        "tags.discard('elderly')\n",
        "tags.discard('vehicle')\n",
        "tags.discard('inhumane-treatment')\n",
        "tags.discard('journalist')\n",
        "tags.discard('throw')\n",
        "tags.discard('explosive')\n",
        "tags.discard('threaten')\n",
        "tags.discard('horse')\n",
        "tags.discard('shove')\n",
        "tags.discard('child')\n",
        "tags.discard('shield')\n",
        "tags.discard('dog')\n",
        "tags.discard('knee')\n",
        "tags.discard('protester')\n",
        "tags.discard('gun')\n",
        "tags.discard('conceal')\n",
        "tags.discard('bystander')\n",
        "tags.discard('grab')\n",
        "tags.discard('push')\n",
        "tags.discard('zip-tie')\n",
        "tags.discard('spray')\n",
        "tags.discard('drive')\n",
        "tags.discard('person-with-disability')\n",
        "tags.discard('celebrity')\n",
        "tags.discard('projectile')\n",
        "tags.discard('beat')\n",
        "newtags = set()\n",
        "for tag in tags:\n",
        "  tag = newtags.add(tag.replace('-',' '))\n",
        "tags = newtags\n",
        "print(tags)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'', 'knee-on-neck', 'baton', 'tear-gas-canister', 'property-destruction', 'throw', 'beat', 'journalist', 'lgbtq+', 'shield', 'foam-bullet', 'bean-bag', 'tase', 'death', 'lrad', 'elderly', 'knee', 'zip-tie', 'wooden-bullet', 'tear-gas', 'politician', 'kick', 'bystander', 'shove', 'incitement', 'non-protest', 'spray', 'tackle', 'conceal', 'pregnant', 'grab', 'horse', 'punch', 'protester', 'inhumane-treatment', 'push', 'celebrity', 'abuse-of-power', 'pepper-spray', 'legal-observer', 'body-cam', 'rubber-bullet', 'live-round', 'child', 'marking-round', 'drive', 'vehicle', 'homeless', 'sexual-assault', 'person-with-disability', 'hide-badge', 'taser', 'headlock', 'gas', 'gun', 'choke', 'strike', 'bike', 'threaten', 'arrest', 'medic', 'pepper-ball', 'explosive', 'dog', 'shoot', 'projectile', 'racial-profiling', 'mace', 'stun-grenade'}\n",
            "{'sexual assault', 'baton', 'knee on neck', 'foam bullet', 'death', 'stun grenade', 'tase', 'lrad', 'kick', 'tackle', 'abuse of power', 'punch', 'body cam', 'bean bag', 'marking round', 'rubber bullet', 'property destruction', 'pepper ball', 'pepper spray', 'live round', 'tear gas', 'headlock', 'taser', 'gas', 'choke', 'hide badge', 'arrest', 'wooden bullet', 'mace'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xu5hSlDW3G6y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "22b5e143-afba-4fa6-e380-01dff71b33b2"
      },
      "source": [
        "# get the url of the reddit post\n",
        "for url in df['url']:\n",
        "  # get the HTML from the url\n",
        "  try:\n",
        "    r = requests.get(url, timeout=10)\n",
        "  except:\n",
        "    continue\n",
        "  soup = BeautifulSoup(r.text)\n",
        "  # get tags from metadata for the site\n",
        "  sitetags = set()\n",
        "  for meta in soup.find_all('meta'):\n",
        "    if meta is None:\n",
        "      continue\n",
        "    meta = str(meta)\n",
        "    meta = meta.lower()\n",
        "    meta = re.sub('[\\W_]+',' ', meta)\n",
        "    for tag in str(meta).split():\n",
        "      sitetags.add(tag)\n",
        "  tags_final = sitetags & tags\n",
        "  if tags_final:\n",
        "    # some matches found, print title and matched tags\n",
        "    print(soup.title.text.strip(), tags_final)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Deputy involved in dog bite arrest ordered strip searches on women {'arrest'}\n",
            "Gunfire in a Tallahassee parking lot leads to arrest of armed couple, complaints of racism {'arrest'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzoCjoYEyxI3",
        "colab_type": "text"
      },
      "source": [
        "## Old `requests` based text grabbing function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtECtipJWHS8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test grabbing the contents of the articles themselves to imporve spaCy NLP\n",
        "# get the url of the reddit post\n",
        "content_list = []\n",
        "df_snip = df['url']\n",
        "for id_url in df_snip:\n",
        "  # get the HTML from the url\n",
        "  try:\n",
        "    r = requests.get(id_url, timeout=10)\n",
        "  except:\n",
        "    content_list.append('')\n",
        "    continue\n",
        "  soup = BeautifulSoup(r.text)\n",
        "  # get text from website\n",
        "  output_text = \" \".join([x.text for x in soup.find_all('p')])\n",
        "  output_text = re.sub(\"[^a-zA-Z0-9.,']+\", ' ', output_text).strip()\n",
        "  content_list.append(output_text)\n",
        "\n",
        "print(df.shape, len(content_list))\n",
        "df['text'] = content_list\n",
        "df = df[df['text'] != '']\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftcMBTf6y-4r",
        "colab_type": "text"
      },
      "source": [
        "## New `newspaper3k` based text extraction system"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68IbV-_nzGX3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set up future columns\n",
        "content_list = []\n",
        "date_list = []\n",
        "tokens_list = []\n",
        "df_snip = df['url']\n",
        "# go through each URL and use newspaper3k to extract data\n",
        "for id_url in df_snip:\n",
        "  # use newspaper3k to extract text\n",
        "  article = Article(id_url)\n",
        "  article.download()\n",
        "  # if the article doesn't download, the error is thrown in parse()\n",
        "  try:\n",
        "    article.parse()\n",
        "  except:\n",
        "    # add null values to show no connection\n",
        "    content_list.append(None)\n",
        "    date_list.append(None)\n",
        "    continue\n",
        "  content_list.append(article.text)\n",
        "  # this will be null if newspaper3k can't find it\n",
        "  date_list.append(article.publish_date)\n",
        "df['text'] = content_list\n",
        "df['date'] = date_list"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTGb0g8-rgpn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "outputId": "989c1e15-4adb-42ce-f97c-481cb4effd2e"
      },
      "source": [
        "# show results\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100, 5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>url</th>\n",
              "      <th>text</th>\n",
              "      <th>date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ilsnn1</td>\n",
              "      <td>Rochester police officer tells activist she's ...</td>\n",
              "      <td>https://www.wxxinews.org/post/rochester-police...</td>\n",
              "      <td>News of the death of Daniel Prude after he was...</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>iltx3x</td>\n",
              "      <td>Drone drops hundreds of bags of cannabis in Te...</td>\n",
              "      <td>https://www.jpost.com/israel-news/drone-drops-...</td>\n",
              "      <td>A drone drops hundreds of bags of cannabis in ...</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ill2g8</td>\n",
              "      <td>U.S. court: Mass surveillance program exposed ...</td>\n",
              "      <td>https://www.reuters.com/article/us-usa-nsa-spy...</td>\n",
              "      <td>FILE PHOTO: Edward Snowden gestures as he spea...</td>\n",
              "      <td>2020-09-03 05:21:24+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ilqqqf</td>\n",
              "      <td>US gives first-ever OK for small commercial nu...</td>\n",
              "      <td>https://apnews.com/910766c07afd96fbe2bd875e160...</td>\n",
              "      <td>BOISE, Idaho (AP) — U.S. officials have for th...</td>\n",
              "      <td>2020-09-02 21:53:55+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ilg8xj</td>\n",
              "      <td>COVID-19 has killed more police officers this ...</td>\n",
              "      <td>https://www.seattletimes.com/nation-world/covi...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       id  ...                       date\n",
              "0  ilsnn1  ...                       None\n",
              "1  iltx3x  ...                       None\n",
              "2  ill2g8  ...  2020-09-03 05:21:24+00:00\n",
              "3  ilqqqf  ...  2020-09-02 21:53:55+00:00\n",
              "4  ilg8xj  ...                       None\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ek1JUmDSrp4X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "b35b3484-160a-4d5d-be5c-95654de14331"
      },
      "source": [
        "# show losses\n",
        "df.isnull().sum()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id        0\n",
              "title     0\n",
              "url       0\n",
              "text      5\n",
              "date     26\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_9xY3gI1mTp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "outputId": "4df0d280-7389-423e-ac9f-10ce1b71d13a"
      },
      "source": [
        "# Remove all entries with missing data\n",
        "df = df.dropna()\n",
        "print(df.shape)\n",
        "df = df.reset_index()\n",
        "df = df.drop(columns='index')\n",
        "df.head()"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(74, 5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>url</th>\n",
              "      <th>text</th>\n",
              "      <th>date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ill2g8</td>\n",
              "      <td>U.S. court: Mass surveillance program exposed ...</td>\n",
              "      <td>https://www.reuters.com/article/us-usa-nsa-spy...</td>\n",
              "      <td>FILE PHOTO: Edward Snowden gestures as he spea...</td>\n",
              "      <td>2020-09-03 05:21:24+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ilqqqf</td>\n",
              "      <td>US gives first-ever OK for small commercial nu...</td>\n",
              "      <td>https://apnews.com/910766c07afd96fbe2bd875e160...</td>\n",
              "      <td>BOISE, Idaho (AP) — U.S. officials have for th...</td>\n",
              "      <td>2020-09-02 21:53:55+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ilrt2x</td>\n",
              "      <td>Investigation into Chinese shipments leads to ...</td>\n",
              "      <td>https://www.masslive.com/news/2020/09/investig...</td>\n",
              "      <td>An investigation into items shipped from China...</td>\n",
              "      <td>2020-09-02 15:23:11.546000+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>iletck</td>\n",
              "      <td>Boston police officers allegedly committed ove...</td>\n",
              "      <td>https://www.boston.com/news/crime/2020/09/02/b...</td>\n",
              "      <td>Nine current and former Boston Police officers...</td>\n",
              "      <td>2020-09-02 00:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ilsl4z</td>\n",
              "      <td>Zimbabwe: Chinese Invade Hwange National Park ...</td>\n",
              "      <td>https://allafrica.com/stories/202009030350.html</td>\n",
              "      <td>Two Chinese companies are reportedly exploring...</td>\n",
              "      <td>2020-09-03 09:25:53+00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       id  ...                              date\n",
              "0  ill2g8  ...         2020-09-03 05:21:24+00:00\n",
              "1  ilqqqf  ...         2020-09-02 21:53:55+00:00\n",
              "2  ilrt2x  ...  2020-09-02 15:23:11.546000+00:00\n",
              "3  iletck  ...               2020-09-02 00:00:00\n",
              "4  ilsl4z  ...         2020-09-03 09:25:53+00:00\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRJh6q170sjQ",
        "colab_type": "text"
      },
      "source": [
        "## Gather location information"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ESpojRIn4OX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "d9c9e6fd-40b0-445e-d1e3-67d3ad14d380"
      },
      "source": [
        "locs_df = pd.read_csv('cities_states.csv')\n",
        "def lowerify(text):\n",
        "  return text.lower()\n",
        "locs_df = locs_df.drop(columns=['Unnamed: 0','country'])\n",
        "locs_df['city_ascii'] = locs_df['city_ascii'].apply(lowerify)\n",
        "locs_df['admin_name'] = locs_df['admin_name'].apply(lowerify)\n",
        "locs_df.head()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>city_ascii</th>\n",
              "      <th>admin_name</th>\n",
              "      <th>lat</th>\n",
              "      <th>lng</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>new york</td>\n",
              "      <td>new york</td>\n",
              "      <td>40.6943</td>\n",
              "      <td>-73.9249</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>los angeles</td>\n",
              "      <td>california</td>\n",
              "      <td>34.1139</td>\n",
              "      <td>-118.4068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>chicago</td>\n",
              "      <td>illinois</td>\n",
              "      <td>41.8373</td>\n",
              "      <td>-87.6862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>miami</td>\n",
              "      <td>florida</td>\n",
              "      <td>25.7839</td>\n",
              "      <td>-80.2102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>dallas</td>\n",
              "      <td>texas</td>\n",
              "      <td>32.7936</td>\n",
              "      <td>-96.7662</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    city_ascii  admin_name      lat       lng\n",
              "0     new york    new york  40.6943  -73.9249\n",
              "1  los angeles  california  34.1139 -118.4068\n",
              "2      chicago    illinois  41.8373  -87.6862\n",
              "3        miami     florida  25.7839  -80.2102\n",
              "4       dallas       texas  32.7936  -96.7662"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Li27pVEO0yot",
        "colab_type": "text"
      },
      "source": [
        "## Old `collections` based approach"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baUxsAfguUx6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "ecb853bb-cf08-4b58-e1d0-7bd8d242a100"
      },
      "source": [
        "from collections import Counter\n",
        "import re\n",
        "\n",
        "\n",
        "# get list of states\n",
        "states_list = list(locs_df.admin_name.unique())\n",
        "states_map = {}\n",
        "# for each state, map their respective cities\n",
        "for state in states_list:\n",
        "  states_map[state] = locs_df[locs_df['admin_name'] == state]['city_ascii'].to_list()\n",
        "\n",
        "# get a list of tokens from the text\n",
        "test_tokens = re.sub('[\\W]+',' ',df['text'][3]).lower().split()\n",
        "\n",
        "# put the tokens into a Counter\n",
        "c = Counter(test_tokens)\n",
        "\n",
        "# Check, for each state, which ones come back with a value of more than one\n",
        "state_counts = {}\n",
        "for state in states_list:\n",
        "  if c[state] > 0:\n",
        "    state_counts[state] = c[state]\n",
        "\n",
        "print(test_tokens[:20])\n",
        "print(state_counts)\n",
        "\n",
        "city_max = max(state_counts, key=state_counts.get)\n",
        "city_counts = {}\n",
        "for city in states_map[city_max]:\n",
        "  if c[city] > 0:\n",
        "    city_counts[city] = c[city]\n",
        "\n",
        "print(states_map[city_max])\n",
        "print(city_counts)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['boise', 'idaho', 'ap', 'u', 's', 'officials', 'have', 'for', 'the', 'first', 'time', 'approved', 'a', 'design', 'for', 'a', 'small', 'commercial', 'nuclear', 'reactor']\n",
            "{'utah': 5, 'idaho': 5}\n",
            "['salt lake city', 'ogden', 'provo', 'west valley city', 'st. george', 'west jordan', 'logan', 'orem', 'taylorsville', 'kearns', 'midvale', 'white city', 'sandy', 'layton', 'south jordan', 'lehi', 'millcreek', 'murray', 'draper', 'bountiful', 'riverton', 'spanish fork', 'herriman', 'pleasant grove', 'roy', 'cedar city', 'tooele', 'cottonwood heights', 'springville', 'eagle mountain', 'kaysville', 'clearfield', 'holladay', 'saratoga springs', 'american fork', 'syracuse', 'magna', 'washington', 'south salt lake', 'farmington', 'heber', 'clinton', 'north salt lake', 'hurricane', 'payson', 'vernal', 'north ogden', 'brigham city', 'highland', 'centerville', 'south ogden', 'park city', 'west haven', 'bluffdale', 'price', 'santaquin', 'smithfield', 'woods cross', 'tremonton', 'lindon', 'north logan', 'west point', 'alpine', 'cedar hills', 'pleasant view', 'mapleton', 'stansbury park', 'washington terrace', 'riverdale', 'ivins', 'salem', 'hyrum', 'richfield', 'santa clara', 'providence', 'south weber', 'moab', 'farr west', 'nibley', 'plain city', 'enoch', 'ephraim', 'roosevelt', 'harrisville', 'snyderville', 'fruit heights', 'vineyard', 'nephi', 'west bountiful', 'sunset', 'midway', 'hooper', 'grantsville', 'summit park']\n",
            "{}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75MuOKN203J2",
        "colab_type": "text"
      },
      "source": [
        "## New `spacy` based location extraction method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2qsY-aB3_UT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "\n",
        "\n",
        "# prep spacy\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "# for each article, perform NLP on its text\n",
        "tokens_list = []\n",
        "for text in df['text']:\n",
        "  doc = nlp(text)\n",
        "\n",
        "  ents = [(e.text, e.label_) for e in doc.ents if e.label_ == 'GPE']\n",
        "  tokens_list.append(ents)\n",
        "\n",
        "df['tokens'] = tokens_list"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wb_8Rr3l5tIM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        },
        "outputId": "33fe762c-3a9f-4f90-8c0e-67cd8909d99c"
      },
      "source": [
        "# what's the results?\n",
        "df['tokens'][2]"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('China', 'GPE'),\n",
              " ('Massachusetts', 'GPE'),\n",
              " ('the United States', 'GPE'),\n",
              " ('China', 'GPE'),\n",
              " ('China', 'GPE'),\n",
              " ('Massachusetts', 'GPE'),\n",
              " ('Massachusetts', 'GPE'),\n",
              " ('Syracuse', 'GPE'),\n",
              " ('New York', 'GPE'),\n",
              " ('U.S.', 'GPE'),\n",
              " ('Massachusetts', 'GPE'),\n",
              " ('U.S.', 'GPE'),\n",
              " ('China', 'GPE'),\n",
              " ('Springfield', 'GPE'),\n",
              " ('Massachusetts', 'GPE'),\n",
              " ('U.S.', 'GPE'),\n",
              " ('China', 'GPE'),\n",
              " ('China', 'GPE'),\n",
              " ('Swansea', 'GPE'),\n",
              " ('East Bridgewater', 'GPE'),\n",
              " ('China', 'GPE'),\n",
              " ('Wrentham', 'GPE'),\n",
              " ('the U.S. Mail', 'GPE'),\n",
              " ('Winthrop', 'GPE'),\n",
              " ('Grasso', 'GPE'),\n",
              " ('Pagliuca', 'GPE'),\n",
              " ('Suffolk County', 'GPE'),\n",
              " ('Worcester', 'GPE'),\n",
              " ('China', 'GPE'),\n",
              " ('marijuana', 'GPE')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fi1ehOn36jon",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}